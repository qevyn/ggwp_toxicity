{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota Dataset Notebook 2 - Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers:\n",
    "* Additional preprocessing\n",
    "* Additional features\n",
    "* Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import langdetect as ld\n",
    "from textblob import TextBlob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Notebook 1\n",
    "* Finding the language of each text and getting the English rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1005.12122</td>\n",
       "      <td>9</td>\n",
       "      <td>ладно гг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1005.85442</td>\n",
       "      <td>9</td>\n",
       "      <td>изи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1008.65372</td>\n",
       "      <td>9</td>\n",
       "      <td>од</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1010.51992</td>\n",
       "      <td>9</td>\n",
       "      <td>ебаный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1013.91912</td>\n",
       "      <td>9</td>\n",
       "      <td>мусор на войде</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match        time  slot            text\n",
       "0      0  1005.12122     9       ладно гг \n",
       "1      0  1005.85442     9             изи\n",
       "2      0  1008.65372     9              од\n",
       "3      0  1010.51992     9          ебаный\n",
       "4      0  1013.91912     9  мусор на войде"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dota2_chat_messages.csv', nrows=50000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling languages\n",
    "langs = np.zeros(len(df)).astype(str)\n",
    "i = -1\n",
    "for message in df['text'].values:\n",
    "    i += 1\n",
    "    try:\n",
    "        langs[i] = ld.detect(message)\n",
    "    except:\n",
    "        continue\n",
    "df['language'] = langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing some languages due to acronyms\n",
    "lang_fix = df.copy()\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('(ez)|(Ez)|(EZ)'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('(lol)|(Lol)|(LOL)'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('(gg)|(Gg)|(GG)'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('(ty)|(Ty)|(TY)'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('(xD)|(XD)'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('[Rr]eport'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('STUPID|[Ss]tupid'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('[Ff][Uu][Cc][Kk]|[Ss]hit'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('[Nn][Oo][Oo][Bb]'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('retard|RETARD'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('pls|stfu|omg|OMG|wtf|WTF|wp|guys|kill|KILL|god|feed|FEED|btw'),'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('idiot|IDIOT|defend|dumb|end'), 'en')\n",
    "lang_fix = lang_fix.mask(df['text'].str.contains('good|game|nice|thx|THX'), 'en')\n",
    "df['language'] = lang_fix['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-131.14018</td>\n",
       "      <td>0</td>\n",
       "      <td>twitch.tv/rage_channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>1563.18490</td>\n",
       "      <td>0</td>\n",
       "      <td>fast and furious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>1757.51320</td>\n",
       "      <td>0</td>\n",
       "      <td>too fas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>1996.39360</td>\n",
       "      <td>8</td>\n",
       "      <td>idiot drow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2006.29390</td>\n",
       "      <td>2</td>\n",
       "      <td>no idiot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    match        time  slot                    text\n",
       "9       1  -131.14018     0  twitch.tv/rage_channel\n",
       "29      2  1563.18490     0        fast and furious\n",
       "30      2  1757.51320     0                 too fas\n",
       "31      2  1996.39360     8              idiot drow\n",
       "32      2  2006.29390     2                no idiot"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng = df[df['language']=='en'].drop('language', axis=1)\n",
    "eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Notebook 2 Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Preprocesssing\n",
    "* Dropping links\n",
    "* Dropping stop words\n",
    "* Dropping words that do not appear often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-131.14018</td>\n",
       "      <td>0</td>\n",
       "      <td>twitch.tv/rage_channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>1563.18490</td>\n",
       "      <td>0</td>\n",
       "      <td>fast and furious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>1757.51320</td>\n",
       "      <td>0</td>\n",
       "      <td>too fas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>1996.39360</td>\n",
       "      <td>8</td>\n",
       "      <td>idiot drow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2006.29390</td>\n",
       "      <td>2</td>\n",
       "      <td>no idiot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    match        time  slot                    text\n",
       "9       1  -131.14018     0  twitch.tv/rage_channel\n",
       "29      2  1563.18490     0        fast and furious\n",
       "30      2  1757.51320     0                 too fas\n",
       "31      2  1996.39360     8              idiot drow\n",
       "32      2  2006.29390     2                no idiot"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14649, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current Version 1 df\n",
    "eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14635, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping links\n",
    "eng = eng.drop(eng[eng['text'].str.contains(\"(\\.tv)\")].index).drop(eng[eng['text'].str.contains(\"(\\.com)\")].index)\n",
    "eng.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurring issues caused by the dataset of 21 million rows are due to limited space and long runtimes. A possible way to combat this may be to drop stop words. Stop words are commonly used words, such as \"the\", \"a\", \"an\", \"in\", etc. Natural Language Toolkit's list of stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Loading stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the stop words \"you\" and \"you're\" will not be taken out. It may be useful to see if words are directed at other teammates in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " \"you've\",\n",
       " \"you'll\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stopwords.remove(\"you\")\n",
    "stopwords.remove(\"you're\")\n",
    "stopwords.remove(\"yourself\")\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There will be 176 different stop words dropped.\n"
     ]
    }
   ],
   "source": [
    "print(\"There will be {} different stop words dropped.\".format(len(stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping stop words\n",
    "def drop_stop_words(text):\n",
    "    \"\"\"Drops stop words from a line of text.\"\"\"\n",
    "    text = text.split(\" \")\n",
    "    nonstop_words = [word for word in text if word not in stopwords]\n",
    "    string = \"\"\n",
    "    for word in nonstop_words:\n",
    "        string += word + \" \"\n",
    "    return string[:len(string)-1]\n",
    "\n",
    "eng['text'] = eng['text'].apply(drop_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['notice', 'shop', 'weak', 'lols', 'kak', 'play,', 'ezzzzzzzz', 'dope',\n",
       "       'falling', 'ld', 'cooldown', 'may', 'rs', 'question', 'hg', 'place,',\n",
       "       'ignore', 'ho', 'shithead', 'lo', 'curry', 'aleatory', 'incase',\n",
       "       'gg,wp', 'celeb', 'mnice', 'weather', 'iq', 'recomiendo', 'usless'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding words that are only used once or twice\n",
    "words = []\n",
    "for row in eng['text'].str.split(\" \"):\n",
    "    for word in row:\n",
    "        words.append(word)\n",
    "word_counts = pd.Series(words).str.lower().value_counts()\n",
    "rare_words = word_counts[word_counts < 3].index\n",
    "rare_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There will be 4386 different rarely used words dropped.\n"
     ]
    }
   ],
   "source": [
    "print(\"There will be {} different rarely used words dropped.\".format(len(rare_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rare_words(text):\n",
    "    \"\"\"Drops rare words from a line of text.\"\"\"\n",
    "    text = text.split(\" \")\n",
    "    nonrare_words = [word for word in text if word.lower() not in rare_words]\n",
    "    string = \"\"\n",
    "    for word in nonrare_words:\n",
    "        string += word + \" \"\n",
    "    return string[:len(string)-1]\n",
    "\n",
    "eng['text'] = eng['text'].apply(drop_rare_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Feature Engineering\n",
    "* Explicit keywords\n",
    "* Word embedding → word2vec\n",
    "\n",
    "Like before, **this is to explore different features, methods to gain different features, and information** we can gain from them. No features are finalized within this notebook, along with the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of offensive language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"**Description: A list of 1,300+ English terms that could be found offensive.** The list contains some words that many people won't find offensive, but it's a good start for anybody wanting to block offensive or profane terms on their Site.\"\n",
    "* From Luis von Ahn's Research Group: _https://www.cs.cmu.edu/~biglou/resources/bad-words.txt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abbo', 'abo', 'abortion', 'abuse', 'addict', 'addicts', 'adult',\n",
       "       'africa', 'african', 'alla', 'allah', 'alligatorbait', 'amateur',\n",
       "       'american', 'anal', 'analannie', 'analsex', 'angie', 'angry',\n",
       "       'anus', 'arab', 'arabs', 'areola', 'argie', 'aroused', 'arse',\n",
       "       'arsehole', 'asian', 'ass', 'assassin'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of potentially offensive words from the link above\n",
    "bad_words = pd.read_fwf(\"bad-words.txt\", header=None)\n",
    "\n",
    "# dropping the words 'dead', 'death', 'sniper', and 'doom' (reasons explained further below this cell)\n",
    "bad_words = bad_words[bad_words[0] != 'dead'][bad_words[0] != 'death'][bad_words[0] != 'sniper'][bad_words[0] != 'doom'].iloc[:,0].values\n",
    "bad_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of offensive words considered: 1379\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of offensive words considered:\", len(bad_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>1563.1849</td>\n",
       "      <td>0</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>1757.5132</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>1996.3936</td>\n",
       "      <td>8</td>\n",
       "      <td>idiot drow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2006.2939</td>\n",
       "      <td>2</td>\n",
       "      <td>idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>2263.3697</td>\n",
       "      <td>2</td>\n",
       "      <td>lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    match       time  slot        text\n",
       "29      2  1563.1849     0        fast\n",
       "30      2  1757.5132     0            \n",
       "31      2  1996.3936     8  idiot drow\n",
       "32      2  2006.2939     2       idiot\n",
       "37      2  2263.3697     2         lol"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting it back to the original dataset\n",
    "offense = eng.copy()\n",
    "offense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive word</th>\n",
       "      <th>num offensive words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42160</th>\n",
       "      <td>2033</td>\n",
       "      <td>-277.59811</td>\n",
       "      <td>1</td>\n",
       "      <td>hey faggot ass show stupid fuck support</td>\n",
       "      <td>[faggot, ass, stupid, fuck]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>76</td>\n",
       "      <td>2839.95183</td>\n",
       "      <td>7</td>\n",
       "      <td>fucking axe retard cunt</td>\n",
       "      <td>[fucking, retard, cunt]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27655</th>\n",
       "      <td>1327</td>\n",
       "      <td>1942.15502</td>\n",
       "      <td>4</td>\n",
       "      <td>fucking monkey suck dick</td>\n",
       "      <td>[fucking, suck, dick]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29100</th>\n",
       "      <td>1395</td>\n",
       "      <td>2422.90175</td>\n",
       "      <td>1</td>\n",
       "      <td>suck big black cock</td>\n",
       "      <td>[suck, black, cock]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37669</th>\n",
       "      <td>1795</td>\n",
       "      <td>2780.87410</td>\n",
       "      <td>2</td>\n",
       "      <td>fucking shit ass lion</td>\n",
       "      <td>[fucking, shit, ass]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34516</th>\n",
       "      <td>1656</td>\n",
       "      <td>2504.49100</td>\n",
       "      <td>0</td>\n",
       "      <td>fuckin retard shit</td>\n",
       "      <td>[fuckin, retard, shit]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17665</th>\n",
       "      <td>864</td>\n",
       "      <td>2104.47704</td>\n",
       "      <td>7</td>\n",
       "      <td>stupid fuck</td>\n",
       "      <td>[stupid, fuck]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23867</th>\n",
       "      <td>1139</td>\n",
       "      <td>1380.12965</td>\n",
       "      <td>6</td>\n",
       "      <td>wtf back attack</td>\n",
       "      <td>[wtf, attack]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33915</th>\n",
       "      <td>1621</td>\n",
       "      <td>2125.03777</td>\n",
       "      <td>9</td>\n",
       "      <td>you fucking suck wk</td>\n",
       "      <td>[fucking, suck]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33892</th>\n",
       "      <td>1621</td>\n",
       "      <td>167.25917</td>\n",
       "      <td>0</td>\n",
       "      <td>fuck u faggot</td>\n",
       "      <td>[fuck, faggot]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48715</th>\n",
       "      <td>2361</td>\n",
       "      <td>1074.03773</td>\n",
       "      <td>2</td>\n",
       "      <td>fucking retard</td>\n",
       "      <td>[fucking, retard]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48719</th>\n",
       "      <td>2361</td>\n",
       "      <td>1421.15303</td>\n",
       "      <td>2</td>\n",
       "      <td>youre fucking dumb</td>\n",
       "      <td>[fucking, dumb]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12614</th>\n",
       "      <td>594</td>\n",
       "      <td>2125.07260</td>\n",
       "      <td>6</td>\n",
       "      <td>you got shit kid</td>\n",
       "      <td>[shit, kid]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>309</td>\n",
       "      <td>954.63362</td>\n",
       "      <td>8</td>\n",
       "      <td>stupid shit hero</td>\n",
       "      <td>[stupid, shit]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34118</th>\n",
       "      <td>1630</td>\n",
       "      <td>732.00125</td>\n",
       "      <td>3</td>\n",
       "      <td>burn hell</td>\n",
       "      <td>[burn, hell]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       match        time  slot                                     text  \\\n",
       "42160   2033  -277.59811     1  hey faggot ass show stupid fuck support   \n",
       "1491      76  2839.95183     7                  fucking axe retard cunt   \n",
       "27655   1327  1942.15502     4                 fucking monkey suck dick   \n",
       "29100   1395  2422.90175     1                      suck big black cock   \n",
       "37669   1795  2780.87410     2                    fucking shit ass lion   \n",
       "34516   1656  2504.49100     0                       fuckin retard shit   \n",
       "17665    864  2104.47704     7                              stupid fuck   \n",
       "23867   1139  1380.12965     6                          wtf back attack   \n",
       "33915   1621  2125.03777     9                      you fucking suck wk   \n",
       "33892   1621   167.25917     0                            fuck u faggot   \n",
       "48715   2361  1074.03773     2                           fucking retard   \n",
       "48719   2361  1421.15303     2                       youre fucking dumb   \n",
       "12614    594  2125.07260     6                         you got shit kid   \n",
       "6680     309   954.63362     8                        stupid shit hero    \n",
       "34118   1630   732.00125     3                                burn hell   \n",
       "\n",
       "                    offensive word  num offensive words  \n",
       "42160  [faggot, ass, stupid, fuck]                    4  \n",
       "1491       [fucking, retard, cunt]                    3  \n",
       "27655        [fucking, suck, dick]                    3  \n",
       "29100          [suck, black, cock]                    3  \n",
       "37669         [fucking, shit, ass]                    3  \n",
       "34516       [fuckin, retard, shit]                    3  \n",
       "17665               [stupid, fuck]                    2  \n",
       "23867                [wtf, attack]                    2  \n",
       "33915              [fucking, suck]                    2  \n",
       "33892               [fuck, faggot]                    2  \n",
       "48715            [fucking, retard]                    2  \n",
       "48719              [fucking, dumb]                    2  \n",
       "12614                  [shit, kid]                    2  \n",
       "6680                [stupid, shit]                    2  \n",
       "34118                 [burn, hell]                    2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def offensive_word(text):\n",
    "    return [word for word in text.split(\" \") if word in bad_words]\n",
    "\n",
    "offense['offensive word'] = offense['text'].apply(offensive_word)\n",
    "offense['num offensive words'] = offense['offensive word'].apply(len)\n",
    "offense.sort_values('num offensive words', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the number of offensive words **seems to be a suitable indicator of toxicity.**\n",
    "\n",
    "Future possibility: putting a degree of offensiveness to certain words (ie. \"ass\" can be less toxic than \"retard\", and therefore carry less weight)\n",
    "* These weights were later included in the use of Tfidf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Offensive Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 14635 messages, 1261 messages contain offensive language.\n"
     ]
    }
   ],
   "source": [
    "print(\"Out of {} messages, {} messages contain offensive language.\"\n",
    "      .format(len(offense), len(offense[offense['num offensive words'] > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num offensive words\n",
       "0    13374\n",
       "1     1160\n",
       "2       95\n",
       "3        5\n",
       "4        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offense.groupby('num offensive words').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most commonly used offensive words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fuck       192\n",
       "fucking    173\n",
       "wtf        153\n",
       "shit       134\n",
       "kill        97\n",
       "idiot       50\n",
       "retard      50\n",
       "god         28\n",
       "stupid      28\n",
       "killed      25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_words = []\n",
    "for array in offense['offensive word']:\n",
    "    for word in array:\n",
    "        used_words.append(word)\n",
    "\n",
    "print(\"Most commonly used offensive words:\")\n",
    "pd.Series(used_words).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some commonly used \"offensive\" words were: \"dead\", \"death\", \"sniper\", and \"doom\". Given these messages are within gaming contexts, these terms may be highly used without toxicity. For example, a player can tell their team that the enemy is dead. In addition, there are two heroes called Sniper and Doom. These words were dropped when loading the initial bad_word list after looking at the context of these words, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive word</th>\n",
       "      <th>num offensive words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41780</th>\n",
       "      <td>2015</td>\n",
       "      <td>1721.26196</td>\n",
       "      <td>7</td>\n",
       "      <td>dead</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42155</th>\n",
       "      <td>2032</td>\n",
       "      <td>2440.75247</td>\n",
       "      <td>5</td>\n",
       "      <td>gg lc dead</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43389</th>\n",
       "      <td>2086</td>\n",
       "      <td>2587.07080</td>\n",
       "      <td>1</td>\n",
       "      <td>braindead children</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       match        time  slot                text offensive word  \\\n",
       "41780   2015  1721.26196     7                dead             []   \n",
       "42155   2032  2440.75247     5          gg lc dead             []   \n",
       "43389   2086  2587.07080     1  braindead children             []   \n",
       "\n",
       "       num offensive words  \n",
       "41780                    0  \n",
       "42155                    0  \n",
       "43389                    0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offense[offense['text'].str.contains('dead')].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive word</th>\n",
       "      <th>num offensive words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48573</th>\n",
       "      <td>2353</td>\n",
       "      <td>2909.65522</td>\n",
       "      <td>7</td>\n",
       "      <td>deaths</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49554</th>\n",
       "      <td>2411</td>\n",
       "      <td>2045.25720</td>\n",
       "      <td>8</td>\n",
       "      <td>many solo weaver deaths</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49895</th>\n",
       "      <td>2420</td>\n",
       "      <td>2123.45143</td>\n",
       "      <td>9</td>\n",
       "      <td>3 secs you death</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       match        time  slot                     text offensive word  \\\n",
       "48573   2353  2909.65522     7                   deaths             []   \n",
       "49554   2411  2045.25720     8  many solo weaver deaths             []   \n",
       "49895   2420  2123.45143     9         3 secs you death             []   \n",
       "\n",
       "       num offensive words  \n",
       "48573                    0  \n",
       "49554                    0  \n",
       "49895                    0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offense[offense['text'].str.contains('death')].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive word</th>\n",
       "      <th>num offensive words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45125</th>\n",
       "      <td>2168</td>\n",
       "      <td>1045.09310</td>\n",
       "      <td>5</td>\n",
       "      <td>sniper mother fucker</td>\n",
       "      <td>[fucker]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46852</th>\n",
       "      <td>2269</td>\n",
       "      <td>1448.94784</td>\n",
       "      <td>7</td>\n",
       "      <td>report sniper pls</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48403</th>\n",
       "      <td>2346</td>\n",
       "      <td>3062.62750</td>\n",
       "      <td>7</td>\n",
       "      <td>sniper played better u</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       match        time  slot                    text offensive word  \\\n",
       "45125   2168  1045.09310     5    sniper mother fucker       [fucker]   \n",
       "46852   2269  1448.94784     7      report sniper pls              []   \n",
       "48403   2346  3062.62750     7  sniper played better u             []   \n",
       "\n",
       "       num offensive words  \n",
       "45125                    1  \n",
       "46852                    0  \n",
       "48403                    0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offense[offense['text'].str.contains('sniper')].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive word</th>\n",
       "      <th>num offensive words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43923</th>\n",
       "      <td>2113</td>\n",
       "      <td>873.96154</td>\n",
       "      <td>2</td>\n",
       "      <td>doom getting killed 3 ppl</td>\n",
       "      <td>[killed]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45136</th>\n",
       "      <td>2169</td>\n",
       "      <td>966.33073</td>\n",
       "      <td>3</td>\n",
       "      <td>report doom</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>2365</td>\n",
       "      <td>260.70302</td>\n",
       "      <td>6</td>\n",
       "      <td>report doom</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       match       time  slot                       text offensive word  \\\n",
       "43923   2113  873.96154     2  doom getting killed 3 ppl       [killed]   \n",
       "45136   2169  966.33073     3                report doom             []   \n",
       "48850   2365  260.70302     6                report doom             []   \n",
       "\n",
       "       num offensive words  \n",
       "43923                    1  \n",
       "45136                    0  \n",
       "48850                    0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offense[offense['text'].str.contains('doom')].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By match and by player**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match\n",
       "1229     0\n",
       "1513     0\n",
       "1512     0\n",
       "1510     0\n",
       "1507     0\n",
       "        ..\n",
       "1395    14\n",
       "1795    14\n",
       "1125    15\n",
       "227     16\n",
       "121     19\n",
       "Name: num offensive words, Length: 1982, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of offensive words per match\n",
    "bad_word_sum = offense.groupby('match')['num offensive words'].sum().sort_values()\n",
    "bad_word_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, there is/are 1 offensive word(s) said per match.\n"
     ]
    }
   ],
   "source": [
    "print(\"On average, there is/are {} offensive word(s) said per match.\".format(round(bad_word_sum.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match  slot\n",
       "2      0        0\n",
       "1569   6        0\n",
       "1567   4        0\n",
       "       2        0\n",
       "1566   1        0\n",
       "               ..\n",
       "1395   1        9\n",
       "2033   1        9\n",
       "2361   2       11\n",
       "1269   1       12\n",
       "1795   2       13\n",
       "Name: num offensive words, Length: 6217, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_player = offense.groupby(['match', 'slot'])['num offensive words'].sum().sort_values()\n",
    "by_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, there is/are 0 offensive word(s) said per player.\n"
     ]
    }
   ],
   "source": [
    "print(\"On average, there is/are {} offensive word(s) said per player.\".format(round(by_player.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the messages with at least one offensive word, the average time of usage is at the 23 minute mark.\n"
     ]
    }
   ],
   "source": [
    "only_offense = offense[offense['num offensive words'] > 0]\n",
    "print(\"Among the messages with at least one offensive word, the average time of usage is at the {} minute mark.\"\n",
    "      .format(round(only_offense['time'].mean() / 60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of messages with offensive words (negative time): 0.126\n"
     ]
    }
   ],
   "source": [
    "# Negative time\n",
    "time_copy = offense.copy()\n",
    "prop = offense[offense['time'] < 0].sort_values(\"num offensive words\")['num offensive words'].mean()\n",
    "print(\"Proportion of messages with offensive words (negative time):\", round(prop, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of messages with offensive words (0-15 mins): 0.122\n"
     ]
    }
   ],
   "source": [
    "# Within 0-15 minutes\n",
    "prop = offense[(offense['time'] >= 0) & (offense['time'] < 900)].sort_values(\"num offensive words\")['num offensive words'].mean()\n",
    "print(\"Proportion of messages with offensive words (0-15 mins):\", round(prop, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of messages with offensive words (15-30 mins): 0.102\n"
     ]
    }
   ],
   "source": [
    "# Within 15-30 minutes\n",
    "prop = offense[(offense['time'] >= 900) & (offense['time'] < 1800)].sort_values(\"num offensive words\")['num offensive words'].mean()\n",
    "print(\"Proportion of messages with offensive words (15-30 mins):\", round(prop, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of messages with offensive words (30+ mins): 0.072\n"
     ]
    }
   ],
   "source": [
    "# Over 30 minutes\n",
    "prop = offense[(offense['time'] >= 1800)].sort_values(\"num offensive words\")['num offensive words'].mean()\n",
    "print(\"Proportion of messages with offensive words (30+ mins):\", round(prop, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Word Embedding\n",
    "* **Word Embeddings** create \"a representation for words that capture their _meanings, semantic relationships, and the different contexts_ they are used in.\"\n",
    "* **Word2vec** is a combination of the continuous bag of words and skip-gram models. Both of these models associate weights to word. CBOW predicts probabilities of words given a context. Skip-gram predicts the context given a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = eng['text'].str.lower().str.split(\" \").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81617, 130520)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# loading the Word2Vec model\n",
    "model = Word2Vec(sg=1, min_count=1, window=3, size=100, workers=4)\n",
    "model.build_vocab(messages)\n",
    "model.train(sentences=messages, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('get', 0.9993589520454407),\n",
       " ('nice', 0.9993569254875183),\n",
       " ('the', 0.9993484020233154),\n",
       " ('4', 0.999345600605011),\n",
       " ('last', 0.9993374943733215),\n",
       " ('5', 0.9993152618408203),\n",
       " ('de', 0.9993113279342651),\n",
       " ('kill', 0.999302327632904),\n",
       " ('time', 0.9992989301681519),\n",
       " ('shit', 0.9992865324020386)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('trash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fast', '', 'idiot', 'drow', 'lol', 'commend', 'me', 'ty', 'ez', 'wtf']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.wv.vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'trash' and 'garbage' is 0.9980788826942444\n"
     ]
    }
   ],
   "source": [
    "similar = model.similarity('trash', 'garbage')\n",
    "print(\"Similarity between 'trash' and 'garbage' is {}\".format(similar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Being new to word embedding, the Word2Vec work above was to explore its functionality. Word2Vec will be more involved in future notebooks.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
